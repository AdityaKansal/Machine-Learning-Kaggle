{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n!pip install keras==2.2.3 \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed92bbb69ca8c8621ace1bb227c06bef122d6de0"},"cell_type":"code","source":"#importing libraires\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom skimage.transform import resize\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras.models import Sequential\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.activations import relu,softmax\n\nfrom tensorflow.python.keras.applications import ResNet50\nfrom keras.applications import VGG16\n\n\n#Image Augmentation libraries\nfrom skimage.util import random_noise\nfrom skimage.util import invert\nfrom skimage.transform import rotate\nfrom skimage.exposure import rescale_intensity\nfrom skimage.exposure import adjust_gamma\nfrom skimage.exposure import adjust_log\nfrom skimage.exposure import adjust_sigmoid\nfrom scipy.ndimage import uniform_filter","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5be88d7b616c7cd273d3eb1b4319f9e4bc98cd2"},"cell_type":"markdown","source":"## Lets see what all we got as input"},{"metadata":{"_uuid":"289f17500eecb2bc8097ce8022ebe359b1931dbf"},"cell_type":"markdown","source":"### Image to ID Mapping"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\nprint('The shape of train df is ',train_df.shape)\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12931f92159fe37ab7882d743a5850d14ca4700b"},"cell_type":"code","source":"print('Total unique kinds of images are ', train_df['Image'].nunique())\nprint('Total unique kinds of ids are ', train_df['Id'].nunique())\nids_count = train_df.groupby('Id').count().reset_index().sort_values(['Image'],ascending = False)\nids_count.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c19968aa75fd468da2cd47242ea4d734100b4630"},"cell_type":"code","source":"#Training set would be only those images which has the whale ID with them\ntrain_df_with_ids = train_df[(train_df['Id'] != 'new_whale')]\ntrain_df_with_ids = train_df_with_ids.reset_index()[['Image','Id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6846dd1cd16ada1ec1ce1572cdff691dd5265ae"},"cell_type":"code","source":"train_df_with_ids.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05ce7536c2b221bcc6ffd407e9a139851d63cffc"},"cell_type":"code","source":"train_df_with_ids.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f72bc90e6c3185d900c717a0e6c14e84142ee7e"},"cell_type":"code","source":"#Augmentation method\naug_func_count = 2\n\n#random noise\ndef random_noise_func(img):\n    new_img = random_noise(img)\n    return new_img\n\n#inversion\ndef invert_func(img):\n    new_img = invert(img)\n    return new_img\n\n#rotate\ndef rotate_func(img):\n    new_img = rotate(img,15)\n    return new_img\n\n\n#change contrast\ndef contrast_func(img):\n    v_min,v_max = np.percentile(img,(0.2,99.8))  \n    new_img = rescale_intensity(img,in_range = (v_min,v_max))\n    return new_img\n\n\n#gamma correction\ndef gamma_func(img):\n    new_img = adjust_gamma(img,gamma = 0.4,gain=0.9)\n    return new_img\n\n\n#log correction\ndef log_func(img):\n    new_img = adjust_log(img)\n    return new_img\n\n\n#Sigmoid Correction\ndef sigmoid_func(img):\n    new_img = adjust_sigmoid(img)\n    return new_img\n\n#Horizontal Flip\ndef H_flip_func(img):\n    new_img = img[:,::-1]\n    return new_img\n\n\n#Blur image\ndef Blur_func(img):\n    new_img = uniform_filter(img,size=(8,8,1))\n    return new_img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"500d572b5a19ce96c9fdcae412f327ff72fa54fc"},"cell_type":"code","source":"image_count_cutoff = 3\nids_need_aug = ids_count[ids_count['Image'] <image_count_cutoff]['Id']\n\nimgs_need_aug = train_df_with_ids[train_df_with_ids['Id'].isin(ids_need_aug)][['Image','Id']].iloc[0:10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9fc5d88524115a767a80c7ba1670d247faa543f"},"cell_type":"code","source":"ids_need_aug.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e349300a689d349950d92956e7c73c1ae0c09a82"},"cell_type":"code","source":"extra_images_count = len(imgs_need_aug) * aug_func_count\nextra_images_count","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce6b69f9531c5a94b7bee0ea6e5adf649c25a204"},"cell_type":"markdown","source":";\n\n##### Based on above distribution, we have lots pf IDs with very less images. Around 2000 IDs have only 1 image (Very High imbalanced Dataset)"},{"metadata":{"_uuid":"df4759bed7bc9d393be50295f1cdcc95c96f1e65"},"cell_type":"markdown","source":"### Lets work on this imbalanced data\n"},{"metadata":{"_uuid":"0202b11ad7feb03727312edddcd404ebb584709d"},"cell_type":"markdown","source":"### First option - Put Ids with less images as new_whale\nIdentify all the whale_ids with images less than 4 or 5 (Decide the cutoffs) We can take less than 4\nReplace thier id with new whale - This way we should have less number of target variables\nWe do not want to train my model for new whale-- Ques - Do softmax function has any not condition\nTrain the model . Output shud be biased towards new_whale in that way-\n\n### Second option - Data augmentation for less images"},{"metadata":{"_uuid":"ec6534ccd4c67771abf0ab78ebb7958a85724199"},"cell_type":"markdown","source":"### Images in train dataset"},{"metadata":{"trusted":true,"_uuid":"139cfc9e1483cc1946299473c69ea69ff01e7aaa"},"cell_type":"code","source":"#test_no = train_df_with_ids.count()[0]  # Choose Test_no as a perfect square number like 16,25,36 because it will help in displaying image in the grid view later\ntest_no = 25\ndf = train_df_with_ids.iloc[:test_no]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f0bc85c7b5fd1002733d31d348c3622821123f6"},"cell_type":"code","source":"\n# # '../input/train/'  contains all the images 25361 images\n# count_of_images = df.shape[0]\n# target_size = (200,200,3)\n\n# #Our final X_train matrix would be shape of Count_of_images,shape of single image\n# #We would take 100,100,3 as a sample image size and interpolate every image to this size\n# X = np.zeros((count_of_images,target_size[0],target_size[1],target_size[2]))\n\n# #Now we shall create a function to read every image and convert it into array and do preprocessing\n\n# def prepare_image(each_image):\n#     img = plt.imread('../input/train/' + each_image)  # Reading each image\n#     img = resize(img,target_size,anti_aliasing=True)\n#     #img_arr = image.img_to_array(img)                                               #converting it to an array \n#     #img_arr = preprocess_input(img_arr)                                             #Preprocessing input\n#     return img\n\n# for i in range(0,count_of_images):\n#     each_img_array = prepare_image(df['Image'][i])\n#     X[i] = each_img_array\n    \n#     if i%1000 == 0:\n#         print('processing image',i+1)\n    \n   \n# print(X.shape)\n\n\n\n\n# '../input/train/'  contains all the images 25361 images\ncount_of_images = df.shape[0] + extra_images_count\ntarget_size = (100,100,3)\n\n#Our final X_train matrix would be shape of Count_of_images,shape of single image\n#We would take 100,100,3 as a sample image size and interpolate every image to this size\nX = np.zeros((count_of_images,target_size[0],target_size[1],target_size[2]))\ny = []\n#Now we shall create a function to read every image and convert it into array and do preprocessing\n\ndef prepare_image(each_image):\n    img = plt.imread('../input/train/' + each_image)  # Reading each image\n    img = resize(img,target_size,anti_aliasing=True)\n    return img\n\ni= 0\nwhile i < count_of_images:\n    if i < df.shape[0]: \n        each_img_array = prepare_image(df['Image'][i])\n        X[i] = each_img_array\n        y.append(df['Id'][i])\n        i = i+1\n    else:\n        j = 0\n        each_img_array = prepare_image(imgs_need_aug['Image'].iloc[j])\n        \n        #random noise\n        new_img_array = random_noise_func(each_img_array)\n        X[i] = new_img_array\n        y.append(imgs_need_aug['Id'].iloc[j])\n        \n        #invert\n        new_img_array = random_noise_func(each_img_array)\n        X[i+1] = new_img_array\n        y.append(imgs_need_aug['Id'].iloc[j])\n        \n#         #rotate\n#         new_img_array = rotate_func(each_img_array)\n#         X[i+2] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n#         #contrast\n#         new_img_array = contrast_func(each_img_array)\n#         X[i+3] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n#         #gamma\n#         new_img_array = gamma_func(each_img_array)\n#         X[i+4] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n#         #log\n#         new_img_array = log_func(each_img_array)\n#         X[i+5] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n        \n#         #sigmoid\n#         new_img_array = sigmoid_func(each_img_array)\n#         X[i+6] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n        \n#         #horizontal\n#         new_img_array = H_flip_func(each_img_array)\n#         X[i+7] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n        \n#         #Blur\n#         new_img_array = Blur_func(each_img_array)\n#         X[i+8] = new_img_array\n#         y.append(imgs_need_aug['Id'].iloc[j])\n        \n\n        i = i + aug_func_count\n        j= j+1\n        \n    if i%1000 == 0:\n        print('processing image',i+1)\n    \n   \nprint(X.shape)\nprint(len(y))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0be32881fcbcab422ab5578739304b0d280a8b1"},"cell_type":"code","source":"#preparing labels - There are total 5005 labels - we shall use label encoders on this\n#And then go ahead with one hot encoding\nle = LabelEncoder()\nohe = OneHotEncoder(categories = 'auto')\n\ny1 = pd.DataFrame(y)\n#y = np.array(df['Id'])\ny = np.array(y1)\ny = le.fit_transform(y)\ny = y.reshape(len(y),1)\ny = ohe.fit_transform(y)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3e04194cb37004d5337e9f33aec55df0130c884"},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb40130f68e02810a9c84bf0c3fecf5506d97adb"},"cell_type":"code","source":"num_classes = y.shape[1]\nprint(num_classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d6bae4a3e112c1666c84b58db5d80d584518fe4"},"cell_type":"markdown","source":"#### Preprocessing images"},{"metadata":{"trusted":true,"_uuid":"be314f47810d26456d8fb58a5d07734c852c315c"},"cell_type":"code","source":"#X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7006046ef2e39962c86f2ff1826358fe8ce4c320"},"cell_type":"code","source":"#X_mean\n# X_mean = np.mean(X,axis =0)\n# plt.imshow(X_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"151ca22d3dea7092f8f4aae46fe0bcec0b03ffba"},"cell_type":"code","source":"#X_variance\n# X_std = np.std(X,axis=0)\n# plt.imshow(X_std)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7718b2603b28b9321ae221cf854594df822d9365"},"cell_type":"markdown","source":"#### Grid View"},{"metadata":{"trusted":true,"_uuid":"e8ae0fe6502b2074bb3065d02710e4ce1e2abf57"},"cell_type":"code","source":"# grid_dim = np.int(np.sqrt(test_no))\n\n\n# fig = plt.figure(figsize=(20,20))\n# for i in range(test_no):\n#     temp = fig.add_subplot(grid_dim,grid_dim,i+1)\n#     temp.set_xticks([])\n#     temp.set_yticks([])\n#     plt.imshow(X[i])\n\n# fig.show()  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"964d73a08b02ce77e04f60b22f1891179a364619"},"cell_type":"markdown","source":"### Model Creation"},{"metadata":{"trusted":true,"_uuid":"3b955ff367c77012f6401186697b82eb56247098"},"cell_type":"code","source":"#resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddee5436296b7cd820aebf964014ce81285184d4"},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfd0c7965391e1825a3e9c8b170ddb1b38eab2b"},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcf93eeb0709bdad6ab98f2673959dc63e9d84c6"},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(filters = 32,kernel_size = (7,7),strides=2,activation= 'relu', padding='valid',name = 'conv0', input_shape = (100, 100, 3)))\n# model.add(Conv2D(16, kernel_size=(3,3),strides=2, activation= 'relu'))\n# model.add(Conv2D(16, kernel_size=(3,3), activation= 'relu'))\n# model.add(Flatten())\n# model.add(Dense(5005, activation= 'softmax'))\n\n# model.summary()\n\n\n\n# model = Sequential()\n\n# model.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (100, 100, 3)))\n\n# model.add(BatchNormalization(axis = 3, name = 'bn0'))\n# model.add(Activation('relu'))\n\n# model.add(MaxPooling2D((2, 2), name='max_pool'))\n# model.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\n# model.add(Activation('relu'))\n# model.add(AveragePooling2D((3, 3), name='avg_pool'))\n\n# model.add(Flatten())\n# model.add(Dense(500, activation=\"relu\", name='rl'))\n# model.add(Dropout(0.8))\n# model.add(Dense(num_classes, activation='softmax', name='sm'))\n\n# model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n# model.summary()\n\n\n#Transfer learning\nresnet_weights_path = 'imagenet'\n\nmodel = Sequential()\n#model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmodel.add(VGG16(include_top=False, pooling='avg', weights=resnet_weights_path))\n#model.add(ResNet50( pooling='avg', weights=resnet_weights_path))\n#model.add(ResNet50(include_top=True, weights='imagenet', input_tensor=None, pooling=None))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmodel.layers[0].trainable = False\n\nmodel.summary()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ea21eba28133dd9a7702f3fa2f606d4d8f624e6"},"cell_type":"code","source":"#fitting model\nmodel.compile(optimizer= 'adam',loss='categorical_crossentropy',metrics= ['accuracy'])\nmodel.fit(X,y,validation_split=0.2, epochs=3,batch_size = 250)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85199ee7ffd80bac8901d34be313b2f8fba6a970"},"cell_type":"code","source":"#Predictions\n# count_of_images = df.shape[0] + extra_images_count\n# target_size = (100,100,3)\n\n# #Our final X_train matrix would be shape of Count_of_images,shape of single image\n# #We would take 100,100,3 as a sample image size and interpolate every image to this size\n# X = np.zeros((count_of_images,target_size[0],target_size[1],target_size[2]))\n# y = []\n#Now we shall create a function to read every image and convert it into array and do preprocessing\n\n# def prepare_image(each_image):\n#     img = plt.imread('../input/test/' + each_image)  # Reading each image\n#     img = resize(img,target_size,anti_aliasing=True)\n#     return img\n\n\n#predictions = model.predict(np.random.rand(2,100,100,3))\n\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ba130bca5b01768b3febf716a09229ddacaa314"},"cell_type":"code","source":"predictions.argsort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c7aca3626407d3bcfd9d2279e035f2d4a311264"},"cell_type":"code","source":"sample_image = image.load_img('../input/train/0000e88ab.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42b1aafff8a917550336f72ffbebb26b99278f5b"},"cell_type":"code","source":"sample_image.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1256df4c2080612f8fb51883215083f599665541"},"cell_type":"code","source":"sample_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6910aabbc9cba4e4e7660d1df25dd207c8c07aa4","_kg_hide-output":false,"_kg_hide-input":false,"scrolled":false},"cell_type":"code","source":"for fig in train_df['Image'][:10]:\n    img = image.load_img('../input/train/' + fig )\n    print(img.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71ef730467c8dd122d731e7a90c2edc0415ca740"},"cell_type":"code","source":"# so we have images avaiabe in different sizes\n#lets make them all in smaller size(less pizels,100, 100, 3)\n#image.load_img('../input/train/0000e88ab.jpg',target_size=(100,100))\nimage_name = '8f9f4e8c2.jpg'\n#image.load_img('../input/train/' + image_name).shape\ntemp = plt.imread(fname = '../input/train/' + image_name, format = 'jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9177699a1033695fb32674a12d312ea63aca53b9"},"cell_type":"code","source":"plt.imshow(temp)\n# temp2 = np.zeros((1050,1310,3))\n# for i in range(3):\n#     temp2[:,:,i] = temp[:,:,i].T\n# temp2.shape\n# plt.imshow(temp2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e04ffb295063dd5528dbb2ac8daf6ef67432e5d"},"cell_type":"code","source":"sample_image_chgd =image.load_img('../input/train/' + image_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c47f198e013408d03345ea6805022e3168324b3"},"cell_type":"code","source":"#image.img_to_array(sample_image_chgd)\nsample_image_chgd.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"061e722dc0f92c41d0c90ca8d3424ed5c31e63bf"},"cell_type":"code","source":"x = image.img_to_array(sample_image_chgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a358d2f49970dd54eedf0b81bdc4ed5ca836fa90"},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"563498afab03ce29c8f3f1ed3f595f3b43db9183"},"cell_type":"code","source":"x[:,:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f7b6d544d165c139673652b2f9b1c7cf77d508b"},"cell_type":"code","source":"y= np.random.randint(low = 1,high= 10,size=(1,4,3))\n#plt.imshow(y)\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bb1a00a36f7e9969ddf77aeda387ee54c54c3ae"},"cell_type":"markdown","source":"## x = preprocess_input(x)\n"},{"metadata":{"trusted":true,"_uuid":"278d1c3efd7b273a7cd13fd260da4088ac5cc429"},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6fd6de85a6c3c0363577deaa4761cdf62c5b68b"},"cell_type":"code","source":"X_train = np.zeros((3, 2, 2, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42bf7668fb47289d24f2f9cdca9058ebddbe6796"},"cell_type":"code","source":"X_train[1] = x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f003f2037107f3e738f04fc2d415d3995408174"},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eabc324d8a2ed1cee0812441f9943f6affc5c33b"},"cell_type":"code","source":"from scipy import misc\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90f7d13ac6e83caf2b8af99bd958ad52429ddef6"},"cell_type":"code","source":"np.ones((2,2,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"447f1792c10e91e3b193d9dddef7b1bf04cce841"},"cell_type":"code","source":"ascent = misc.ascent()\n#pic = np.ones((5,5)*30\n# pic = np.random.randint(0,3,5*5).reshape(5,5)\n# pic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2b3f1ecfc4fa7dd3b0eafa8252872e77229f48e"},"cell_type":"code","source":"ascent.s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9ab00890f05f263d9c61d97a1bd5645ef229209"},"cell_type":"code","source":"plt.imshow(ascent)\n#plt.imshow(pic,cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d275d574c8c637376c083b2126f7aa8e8f8704c5"},"cell_type":"markdown","source":"### Junk Code- Ignore this section"},{"metadata":{"trusted":true,"_uuid":"bdbbb4541fd189e02af51249a9bfb170782eb51e"},"cell_type":"code","source":"#a loop to view multiple images of same id\n'''\nimage_list = [\n'0829ae94e.jpg','10b694367.jpg','180056116.jpg','18f817e48.jpg','2354879ce.jpg','294ab237b.jpg','3d7f4c7d5.jpg','45adc4f95.jpg','4cc7c734b.jpg','4e6c0e6da.jpg','4fa94d7be.jpg','51072b758.jpg','55439f4de.jpg','557c56974.jpg','64fc5e880.jpg','73135d38c.jpg','75ad5e6b0.jpg','82b65b762.jpg'\n]\n\nfor i in range(len(image_list)):\n    image = plt.imread('../input/train/' + image_list[i])\n    print(image.shape[1])\n    plt.imshow(image)\n    plt.figure()\n#plt.imshow(image)\n'''\n\n#appending Resolution of the image with the image ID\ndef get_resolution(img):\n    image = plt.imread('../input/train/' + img)\n    #return image.shape[0],image.shape[1],image.shape[1]\n    return image.shape\n\n# train_df_1['c'] = train_df['Image'][0:5].apply(lambda x : get_resolution(x))\n# #train_df_1['a'],train_df_1['b'],train_df_1['c'] = train_df_1['Image'].apply(lambda x : x[0],x[1],x[2])\n# train_df_1['d'] = train_df_1['Image'].apply(lambda x : x[0])\n#train_df['Image'][0:5].apply(lambda x : get_resolution(x)))\n \n#train_df_1['Res_1'][0:5],train_df_1['Res_2'][0:5],train_df_1['clr_band'][0:5] = train_df['Image'][0:5].apply(lambda x : get_resolution(x))\n'''   \ntrain_df['Resolution'] = train_df['Image'].apply(lambda x : get_resolution(x))\ntrain_df['Res_1'] = train_df['Resolution'].apply(lambda x : x[0])\ntrain_df['Res_2'] = train_df['Resolution'].apply(lambda x : x[1])\ntrain_df['Clr_Band'] = train_df['Resolution'].apply(lambda x : x[2])\n\n'''\n\n#saving this csv\n#train_df.to_csv('Updated_train_1.csv',index = False)\n\n\n# for i in range(test_no):\n#     #plt.figure(figsize=(5, 1)).add_subplot(nrows = 1,ncols = 5,index=i+1)\n#     plt.subplot(1,5,i+1)\n#     plt.xticks([])\n#     plt.yticks([])\n#     plt.imshow(X_array[i])\n    \n# plt.show()\n  \n    \n# def prepare_image(each_image):\n#     img = image.load_img('../input/train/' + each_image,target_size = target_size)  # Reading each image\n#     img_arr = image.img_to_array(img)                                               #converting it to an array \n#     img_arr = preprocess_input(img_arr)                                             #Preprocessing input\n#     return img_arr\n\n\n#dividing data into Train and test\n#X_train.shape\n#y_train.shape\n#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\n\ngrid_dim = np.int(np.sqrt(test_no))\n\n# fig = plt.figure(figsize=(20,20))\n# for i in range(test_no):\n#     temp = fig.add_subplot(grid_dim,grid_dim,i+1)\n#     temp.set_xticks([])\n#     temp.set_yticks([])\n#     plt.imshow(X[i])\n# fig.show()  \n\n#Dimensionality Reductiion\n'''\ndef rgb_to_gray(img):\n    return np.dot(img,[0.299, 0.587, 0.114])\n\nX_bw = np.zeros((X.shape[0],X.shape[1],X.shape[2]))\n                \nfor i in range(X.shape[0]):\n    X_bw[i] = rgb_to_gray(X[i])\nX_bw.shape\n'''\n\n#Normalization - Subtracticting mean and dividing by std\n'''\nX = X- X_mean\nX = X/X_std\n'''\n\n\n#Data Augmentation\n\n#random noise\n# from skimage.util import random_noise\n# img = X[0]    \n# new_img = random_noise(img)\n# plt.imshow(img) \n\n#inversion\n# from skimage.util import invert\n# img = X[0]    \n# new_img = invert(img)\n# plt.imshow(img) \n\n#rotate\n# from skimage.transform import rotate\n# img = X[0]    \n# new_img = rotate(img,30)\n# plt.imshow(img) \n\n\n#change contrast\n# from skimage.exposure import rescale_intensity\n# v_min,v_max = np.percentile(img,(0.2,99.8))\n# new_img = rescale_intensity(img,in_range = (v_min,v_max))\n# plt.imshow(img)\n\n#gamma correction\n# from skimage.exposure import adjust_gamma\n# new_img = adjust_gamma(img,gamma = 0.4,gain=0.9)\n# plt.imshow(img)\n\n\n#log correction\n# from skimage.exposure import adjust_log\n# new_img = adjust_log(img)\n# plt.imshow(img)\n\n#Sigmoid Correction\n# from skimage.exposure import adjust_sigmoid\n# new_img = adjust_sigmoid(img)\n# plt.imshow(img)\n\n\n#Horizontal Flip\n# new_img = img[:,::-1]\n# plt.imshow(img)\n\n\n#Vertical flip\n# new_img = img[::-1,:]\n# plt.imshow(img)\n\n#Blur image\n# from scipy.ndimage import uniform_filter\n# new_img = uniform_filter(img,size=(8,8,1))\n# plt.imshow(img)\n\n\n    \n    \n   \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d70dd2a2691c3be3393e0f4d078cbf843b0dfc2"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}