{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-27T12:27:46.470771Z","iopub.execute_input":"2023-06-27T12:27:46.471267Z","iopub.status.idle":"2023-06-27T12:27:46.486626Z","shell.execute_reply.started":"2023-06-27T12:27:46.471233Z","shell.execute_reply":"2023-06-27T12:27:46.484879Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/link-prediction-outputs-new/sim_score_output (1).csv\n/kaggle/input/dsaa-2023-competition/sample_submission.csv\n/kaggle/input/dsaa-2023-competition/train.csv\n/kaggle/input/dsaa-2023-competition/test.csv\n/kaggle/input/dsaa-2023-competition/nodes/nodes.tsv\n/kaggle/input/link-prediction-outputs-new1/test_sim_score_output (2).csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reading inputs\ntrain = pd.read_csv(\"/kaggle/input/dsaa-2023-competition/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/dsaa-2023-competition/test.csv\")\nnodes = pd.read_csv('/kaggle/input/dsaa-2023-competition/nodes/nodes.tsv',sep ='\\t')\nsample_sub = pd.read_csv(\"/kaggle/input/dsaa-2023-competition/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-27T12:27:46.663018Z","iopub.execute_input":"2023-06-27T12:27:46.664102Z","iopub.status.idle":"2023-06-27T12:27:58.043229Z","shell.execute_reply.started":"2023-06-27T12:27:46.664052Z","shell.execute_reply":"2023-06-27T12:27:58.041725Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### We are using two models - First model will give a score based on adjacent nodes connections and second model will give score based on text similarity between nodes description. Then we will combine both the predictions to give final score","metadata":{}},{"cell_type":"markdown","source":"### Model 1 - Prediction for adjacent nodes (Graph structure)","metadata":{}},{"cell_type":"code","source":"# Graph score\n\n# Total nodes for graph\ntotal_nodes = nodes['id'].dropna().nunique()\n\n#Available edges\ndf_edges = train[train['label'] == 1][['id1','id2']]\n\n\n\n# Graph class with functions for defining graph structure,add edges and a function if some path exist\nclass Graph:\n \n    # init function to declare class variables with V as number of vertices or nodes\n    def __init__(self, V):\n        self.V = V\n        self.adj = [[] for i in range(V)]\n \n     # method to add an undirected edge\n    def addEdge(self, v, w):\n        self.adj[v-1].append(w)\n        self.adj[w-1].append(v)\n        \n    def path_exist(self,u,v,depth=5):\n        \n        if u==v:\n            return 1\n        \n        if u == \"\" or v == \"\":\n            return 0\n\n        connections = self.adj[u-1]\n        for i in connections:\n            if v == i:\n                return 1\n\n        while depth >0:   \n            temp =[]\n            for i in connections:\n                temp.append(self.adj[i-1])\n\n            connections = sum(temp,[])\n\n            for i in connections:\n                if v == i:\n                    return 1\n\n            depth = depth-1\n        return 0    \n\n\n\n\n# Creating Grapgh for training data and adding edges\ng_submission = Graph(total_nodes) # Graph\ndf_edges.apply(lambda x : g_submission.addEdge(x['id1'],x['id2']),axis =1) # Adding edges\n\n# Finding if path exist between test submissiondata nodes upto level 3 depth\ntest['pred_graph'] = test.apply(lambda x: g_submission.path_exist(x['id1'],x['id2'],depth =3),axis =1)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T12:27:58.045940Z","iopub.execute_input":"2023-06-27T12:27:58.046417Z","iopub.status.idle":"2023-06-27T12:29:54.753221Z","shell.execute_reply.started":"2023-06-27T12:27:58.046360Z","shell.execute_reply":"2023-06-27T12:29:54.752006Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Model 2 - Predcition from text similarity scores","metadata":{}},{"cell_type":"code","source":"## All the functions needed for text similairty\n# Similarity Score function\n\ndef sim_score(text1,text2):\n    text1 = set(text1.split(\" \"))\n    text2 = set(text2.split(\" \"))\n    \n    intersection = len(text1 & text2)\n    union = len(text1.union(text2))\n    \n    score = intersection/union\n    return score\n\n# Text cleaning function\nimport re\nimport nltk\n\ndef clean_text(raw_text):\n    \n    #Keep only alphabets and spaces and converting everything to lower case\n    cleaned_text = re.sub('[^a-zA-Z ]+',\"\",raw_text)\n    cleaned_text = \" \".join(cleaned_text.split())\n    cleaned_text = cleaned_text.lower()\n    \n    \n    #Lemmatization - convert them to their root words\n    # Leaving it for now due to computational efficiency\n        \n    return cleaned_text\n\n\n# identify most frequent word in all descriptions ( and remove them from descriptions like stopwords)\n# Raw nodes decription and their cleaning\nnodes_text = nodes.dropna()\nnodes_text = nodes_text.drop_duplicates(subset=['id'])\nnodes_text['cleaned_text'] = nodes_text['text'].apply(lambda x : clean_text(x))\n\n# Getting frequency of each word in all text\nword_freq = {}\n\nnodes_desc_list = nodes_text['cleaned_text'].tolist()   \nfor nodes_desc in nodes_desc_list:\n    for word in nodes_desc.split(' '):\n        if word in word_freq.keys():\n            word_freq[word] = word_freq[word] + 1\n        else:\n            word_freq[word] = 1\n            \nword_freq = pd.DataFrame.from_dict(word_freq.items())\nword_freq.columns = ['word','frequency']\nword_freq = word_freq[word_freq['word'] != '' ]\n\n# Selecting most frequent stopwords\nselected_stopwords = word_freq[word_freq['frequency'] > 40000]['word'].tolist()\n\n\n# Adding these selected stopwords to nltk corpus stopwords\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nstop_words = stop_words + selected_stopwords\n\n#removing stopwords\ndef remove_stopwords(text,stopwords):\n    text_without_stopwords = []\n    for word in text.split(' '):\n        if word in stopwords:\n            pass\n        else:\n            text_without_stopwords.append(word)\n    return \" \".join(text_without_stopwords)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T12:29:54.756314Z","iopub.execute_input":"2023-06-27T12:29:54.756806Z","iopub.status.idle":"2023-06-27T12:31:58.595026Z","shell.execute_reply.started":"2023-06-27T12:29:54.756771Z","shell.execute_reply":"2023-06-27T12:31:58.593284Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# text similarity score\n\n# Get nodes desc across test data\ntest_modified = pd.merge(test,nodes_text[[\"id\",\"text\",\"cleaned_text\"]].rename(columns ={\"id\": \"id1\",\"text\":\"id1_text\",\"cleaned_text\":\"id1_desc\"}),on =['id1'],how = 'left')\n\ntest_modified = pd.merge(test_modified,nodes_text[[\"id\",\"text\",\"cleaned_text\"]].rename(columns ={\"id\": \"id2\",\"text\":\"id2_text\",\"cleaned_text\":\"id2_desc\"}),on =['id2'],how = 'left')\n\n#Get similarity score\ntest_modified['id1_desc'] = test_modified['id1_desc'].apply(lambda x : remove_stopwords(str(x),stop_words))\ntest_modified['id2_desc'] = test_modified['id2_desc'].apply(lambda x : remove_stopwords(str(x),stop_words))\n\ntest_modified['sim_score'] = test_modified.apply(lambda x:sim_score(x['id1_desc'],x['id2_desc']),axis=1)\ntest_modified = test_modified.drop(['id1_text','id1_desc','id2_text','id2_desc'],axis =1)\n\ntest_modified.rename(columns={'pred':'pred_text'},inplace=True)\ntest_modified['pred_text'] = test_modified['sim_score'].apply(lambda x : 1 if x > 0.008 else 0)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T12:31:58.596807Z","iopub.execute_input":"2023-06-27T12:31:58.597198Z","iopub.status.idle":"2023-06-27T12:36:41.401780Z","shell.execute_reply.started":"2023-06-27T12:31:58.597166Z","shell.execute_reply":"2023-06-27T12:36:41.400496Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Merging both predictions","metadata":{}},{"cell_type":"code","source":"final_submission_pred = pd.merge(test,test_modified[['id','id1','id2','sim_score','pred_text']],\n                          on =['id','id1','id2'],how ='inner')\n\nfinal_submission_pred['final_pred'] = final_submission_pred.apply(lambda x : 1 if x['pred_graph'] == 1 else x['pred_text'],axis =1)\nfinal_submission_pred['final_pred'] = final_submission_pred['final_pred'].astype('int') \nsubmission = final_submission_pred[['id','final_pred']].rename(columns = {'final_pred':'label'})\nsubmission.to_csv('submission3.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T12:36:41.404168Z","iopub.execute_input":"2023-06-27T12:36:41.404584Z","iopub.status.idle":"2023-06-27T12:36:46.496164Z","shell.execute_reply.started":"2023-06-27T12:36:41.404545Z","shell.execute_reply":"2023-06-27T12:36:46.494889Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}